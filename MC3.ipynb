{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-E-jqplGoUk"
      },
      "source": [
        "# Reading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dOKWT30FxYCK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "class Normalize01(torch.nn.Module):\n",
        "    \"\"\"Normalizza i valori di un tensore tra 0 e 1.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, img):\n",
        "        min_val, max_val = img.min(), img.max()\n",
        "        return (img - min_val) / (max_val - min_val) if max_val > min_val else torch.zeros_like(img)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '()'\n",
        "\n",
        "def lambda_check_range(x):\n",
        "    return (check_tensor_range(x), x)[1]\n",
        "\n",
        "def check_tensor_range(img):\n",
        "    \"\"\" Controlla se i valori del tensore sono nel range [0,1] dopo ToTensor. \"\"\"\n",
        "    if img.min() < 0 or img.max() > 1:\n",
        "        print(\"Warning: Tensor values are out of range [0,1] after ToTensor\")\n",
        "\n",
        "\n",
        "class PollinateDataset(Dataset):\n",
        "    def __init__(self, csv_file, dataset_folder, channels=('T', 'M', 'N'), selected_ids=None, transform=None):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.dataset_folder = dataset_folder\n",
        "        self.channels = channels\n",
        "        self.transform = transform\n",
        "        self.min_size = (100, 100)  # Dimensione minima richiesta\n",
        "        # Use only selected IDs if provided\n",
        "        if selected_ids is not None:  #lasciare a None per usare tutto il dataset\n",
        "            self.df = self.df[self.df['folder'].isin(selected_ids)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def pad_image_to_min_size(self, image, min_size=(100, 100)):\n",
        "        \"\"\"Aggiunge padding all'immagine se è più piccola delle dimensioni minime richieste.\"\"\"\n",
        "        h, w = image.shape[:2]\n",
        "        pad_h = max(0, min_size[0] - h)\n",
        "        pad_w = max(0, min_size[1] - w)\n",
        "\n",
        "        if pad_h > 0 or pad_w > 0:\n",
        "            # Calcola il padding su ogni lato per centrare l'immagine\n",
        "            top = pad_h // 2\n",
        "            bottom = pad_h - top\n",
        "            left = pad_w // 2\n",
        "            right = pad_w - left\n",
        "\n",
        "            image = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=0)\n",
        "\n",
        "        return image\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        sample_id = str(row['folder'])\n",
        "        label = row['class']\n",
        "        folder_path = os.path.join(self.dataset_folder, sample_id)\n",
        "\n",
        "        imgs = []\n",
        "        for ch in self.channels:\n",
        "            path = os.path.join(folder_path, f\"{sample_id}_{ch}.npy\")\n",
        "            img = np.load(path)\n",
        "            img = self.pad_image_to_min_size(img, self.min_size)\n",
        "            imgs.append(img)\n",
        "\n",
        "        img_stack = np.stack(imgs, axis=0)\n",
        "\n",
        "        # Convert to float32 and normalize to [0,1] if not done already\n",
        "        img_tensor = torch.from_numpy(img_stack).float()\n",
        "        if self.transform:\n",
        "            img_tensor = self.transform(img_tensor)\n",
        "        else:\n",
        "            #img_tensor = torch.from_numpy(img_stack).float()\n",
        "            if img_tensor.max() > 1.0:\n",
        "                img_tensor /= 255.0\n",
        "\n",
        "        return row['folder'], img_tensor, label\n",
        "\n",
        "class PollinateTestDataset(Dataset):\n",
        "    def __init__(self, dataset_folder, channels=('T', 'M', 'N'), transform=None):\n",
        "        self.dataset_folder = dataset_folder\n",
        "        self.channels = channels\n",
        "        self.transform = transform\n",
        "        self.min_size = (100, 100)\n",
        "        # Prendi solo le sottocartelle (ID)\n",
        "        self.ids = sorted([name for name in os.listdir(dataset_folder) if os.path.isdir(os.path.join(dataset_folder, name))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def pad_image_to_min_size(self, image, min_size=(100, 100)):\n",
        "        h, w = image.shape[:2]\n",
        "        pad_h = max(0, min_size[0] - h)\n",
        "        pad_w = max(0, min_size[1] - w)\n",
        "        if pad_h > 0 or pad_w > 0:\n",
        "            top = pad_h // 2\n",
        "            bottom = pad_h - top\n",
        "            left = pad_w // 2\n",
        "            right = pad_w - left\n",
        "            image = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=0)\n",
        "        return image\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample_id = self.ids[idx]\n",
        "        folder_path = os.path.join(self.dataset_folder, sample_id)\n",
        "        imgs = []\n",
        "        for ch in self.channels:\n",
        "            path = os.path.join(folder_path, f\"{sample_id}_{ch}.npy\")\n",
        "            img = np.load(path)\n",
        "            img = self.pad_image_to_min_size(img, self.min_size)\n",
        "            imgs.append(img)\n",
        "        img_stack = np.stack(imgs, axis=0)\n",
        "        img_tensor = torch.from_numpy(img_stack).float()\n",
        "        if self.transform:\n",
        "            img_tensor = self.transform(img_tensor)\n",
        "        else:\n",
        "            if img_tensor.max() > 1.0:\n",
        "                img_tensor /= 255.0\n",
        "        return sample_id, img_tensor\n",
        "\n",
        "dataset_folder = 'myFolder'\n",
        "channels = ('T', 'M', 'N') #da modificare in base alla scelta dei canali\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Lambda(lambda_check_range),\n",
        "    transforms.Resize((224, 224)),  # Porta tutto a 224x224 per il modello (ATTENZIONE: Da modificare in base alla scelta della soluzione)\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    Normalize01(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "testval_transform = transforms.Compose([\n",
        "    transforms.Lambda(lambda_check_range),\n",
        "    transforms.Resize((224, 224)),  # Porta tutto a 224x224 per il modello (ATTENZIONE: Da modificare in base alla scelta della soluzione)\n",
        "    Normalize01(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jnu01DFgGuIt"
      },
      "source": [
        "# Create train, test and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBE-RYzBGtsD",
        "outputId": "04614928-b70b-40ee-f8c7-c7ce18053c87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train acquisizioni: 191, Val: 24, Test: 24\n",
            "Train celle: 5585, Val: 619, Test: 594\n",
            "Train dataset size: 5585\n",
            "Validation dataset size: 619\n",
            "Test dataset size: 594\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "train_folder = os.path.join(dataset_folder, \"train\")\n",
        "\n",
        "# 1. Estrai la lista delle acquisizioni (xxx)\n",
        "all_folders = [name for name in os.listdir(train_folder) if os.path.isdir(os.path.join(train_folder, name))]\n",
        "all_acquisitions = sorted(list(set([folder.split('_')[0] for folder in all_folders])))\n",
        "\n",
        "# 2. Suddividi le acquisizioni in 80% train, 10% val, 10% test\n",
        "train_acq, temp_acq = train_test_split(all_acquisitions, test_size=0.2, random_state=42)\n",
        "val_acq, test_acq = train_test_split(temp_acq, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Train acquisizioni: {len(train_acq)}, Val: {len(val_acq)}, Test: {len(test_acq)}\")\n",
        "\n",
        "# 3. Ottieni le celle (sottocartelle) per ogni split\n",
        "train_ids = [folder for folder in all_folders if folder.split('_')[0] in train_acq]\n",
        "val_ids = [folder for folder in all_folders if folder.split('_')[0] in val_acq]\n",
        "test_ids = [folder for folder in all_folders if folder.split('_')[0] in test_acq]\n",
        "\n",
        "print(f\"Train celle: {len(train_ids)}, Val: {len(val_ids)}, Test: {len(test_ids)}\")\n",
        "\n",
        "# Ora puoi passare questi ID a PollinateDataset come selected_ids\n",
        "train_dataset = PollinateDataset(\n",
        "    csv_file=os.path.join(dataset_folder, 'train.csv'),\n",
        "    dataset_folder=os.path.join(dataset_folder, \"train\"),\n",
        "    channels=channels,\n",
        "    selected_ids=train_ids,\n",
        "    transform=train_transform\n",
        ")\n",
        "val_dataset = PollinateDataset(\n",
        "    csv_file=os.path.join(dataset_folder, 'train.csv'),\n",
        "    dataset_folder=os.path.join(dataset_folder, \"train\"),\n",
        "    channels=channels,\n",
        "    selected_ids=val_ids,\n",
        "    transform=testval_transform\n",
        ")\n",
        "test_dataset = PollinateDataset(\n",
        "    csv_file=os.path.join(dataset_folder, 'train.csv'),\n",
        "    dataset_folder=os.path.join(dataset_folder, \"train\"),\n",
        "    channels=channels,\n",
        "    selected_ids=test_ids,\n",
        "    transform=testval_transform\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGkUnHzYIOxm"
      },
      "source": [
        "# Network Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xznKek8bIQrt"
      },
      "outputs": [],
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "def get_pretrained_resnet(num_classes):\n",
        "    model = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
        "    # Adatta l'ultimo layer per il numero di classi\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "# Define the training function\n",
        "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "    for batch_idx, (ids, data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device).long()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data) #forward\n",
        "        loss = criterion(output, target)  #calcolo loss\n",
        "        loss.backward() #calcolo gradienti\n",
        "        optimizer.step() #agg pesi\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        train_acc += (output.argmax(dim=1) == target).sum().item()\n",
        "    train_acc /= len(train_loader.dataset)\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    return train_loss, train_acc\n",
        "\n",
        "# Define the validation function\n",
        "def validate(model, device, val_loader, criterion):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_acc = 0.0\n",
        "    with torch.no_grad():\n",
        "        for ids, data, target in val_loader:\n",
        "            data, target = data.to(device), target.to(device).long()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            val_loss += loss.item()\n",
        "            val_acc += (output.argmax(dim=1) == target).sum().item()\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_acc /= len(val_loader.dataset)\n",
        "    return val_loss, val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwmpeXI7IUjm"
      },
      "source": [
        "# Train the Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "N9m4n0edIXMo",
        "outputId": "0fb9d084-5f87-4633-8018-fb1e6e757f9b"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 40\u001b[0m\n\u001b[1;32m     29\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#1. WORK ON TRAIN SET\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# FOR EACH BATCH b:\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#     FORWARD STEP -> y_pred = MLP(b)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#     FORWARD STEP -> y_pred = MLP(b)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#     COMPUTE THE LOSS -> Loss = criterion(y_pred, label)\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m val_loss, val_acc \u001b[38;5;241m=\u001b[39m validate(model, device, val_loader, criterion)\n\u001b[1;32m     43\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
            "Cell \u001b[0;32mIn[5], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, criterion, epoch)\u001b[0m\n\u001b[1;32m     13\u001b[0m train_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     14\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (ids, data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     16\u001b[0m     data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/data/dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "Cell \u001b[0;32mIn[1], line 73\u001b[0m, in \u001b[0;36mPollinateDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannels:\n\u001b[1;32m     72\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_image_to_min_size(img, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_size)\n\u001b[1;32m     75\u001b[0m     imgs\u001b[38;5;241m.\u001b[39mappend(img)\n",
            "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/numpy/lib/npyio.py:434\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    432\u001b[0m _ZIP_SUFFIX \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPK\u001b[39m\u001b[38;5;130;01m\\x05\u001b[39;00m\u001b[38;5;130;01m\\x06\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# empty zip files start with this\u001b[39;00m\n\u001b[1;32m    433\u001b[0m N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mMAGIC_PREFIX)\n\u001b[0;32m--> 434\u001b[0m magic \u001b[38;5;241m=\u001b[39m \u001b[43mfid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m magic:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data left in file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "input_dim = 64\n",
        "output_dim = 10\n",
        "lr = 5e-5\n",
        "num_epochs = 50\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize the model, device, optimizer, and criterion\n",
        "num_classes = len(set(train_dataset.df['class']))\n",
        "model = get_pretrained_resnet(num_classes).to(device)\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "val_losses = []\n",
        "val_accs = []\n",
        "best_loss = 0.0\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    # CREATE BATCHES\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "    #1. WORK ON TRAIN SET\n",
        "    # FOR EACH BATCH b:\n",
        "    #     FORWARD STEP -> y_pred = MLP(b)\n",
        "    #     COMPUTE THE LOSS -> Loss = criterion(y_pred, label)\n",
        "    #     COMPUTE THE GRADIENTS\n",
        "    #     UPDATE THE NETWORK\n",
        "    #2. WORK ON VALIDATION SET\n",
        "    # FOR EACH BATCH b:\n",
        "    #     FORWARD STEP -> y_pred = MLP(b)\n",
        "    #     COMPUTE THE LOSS -> Loss = criterion(y_pred, label)\n",
        "    train_loss, train_acc = train(model, device, train_loader, optimizer, criterion, epoch)\n",
        "    val_loss, val_acc = validate(model, device, val_loader, criterion)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Validation Loss: {val_loss:.4f}, Validation Acc: {val_acc:.4f}')\n",
        "\n",
        "    if epoch == 0 or val_loss<best_loss:\n",
        "      best_loss = val_loss\n",
        "      torch.save(model.state_dict(),  'best_weights.pth')\n",
        "\n",
        "# Plot the training curves\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accs, label='Training Accuracy')\n",
        "plt.plot(val_accs, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt_grYZ_IX9S"
      },
      "source": [
        "Final Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdAkmfV7IY7y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20, Train Loss: 0.0211, Train Acc: 0.8514\n",
            "Epoch 2/20, Train Loss: 0.0132, Train Acc: 0.9172\n",
            "Epoch 3/20, Train Loss: 0.0106, Train Acc: 0.9346\n",
            "Epoch 4/20, Train Loss: 0.0096, Train Acc: 0.9429\n",
            "Epoch 5/20, Train Loss: 0.0078, Train Acc: 0.9515\n",
            "Epoch 6/20, Train Loss: 0.0070, Train Acc: 0.9597\n",
            "Epoch 7/20, Train Loss: 0.0063, Train Acc: 0.9666\n",
            "Epoch 8/20, Train Loss: 0.0055, Train Acc: 0.9650\n",
            "Epoch 9/20, Train Loss: 0.0056, Train Acc: 0.9681\n",
            "Epoch 10/20, Train Loss: 0.0046, Train Acc: 0.9731\n",
            "Epoch 11/20, Train Loss: 0.0042, Train Acc: 0.9768\n",
            "Epoch 12/20, Train Loss: 0.0044, Train Acc: 0.9728\n",
            "Epoch 13/20, Train Loss: 0.0038, Train Acc: 0.9766\n",
            "Epoch 14/20, Train Loss: 0.0033, Train Acc: 0.9810\n",
            "Epoch 15/20, Train Loss: 0.0033, Train Acc: 0.9808\n",
            "Epoch 16/20, Train Loss: 0.0025, Train Acc: 0.9865\n",
            "Epoch 17/20, Train Loss: 0.0026, Train Acc: 0.9860\n",
            "Epoch 18/20, Train Loss: 0.0029, Train Acc: 0.9828\n",
            "Epoch 19/20, Train Loss: 0.0030, Train Acc: 0.9832\n",
            "Epoch 20/20, Train Loss: 0.0025, Train Acc: 0.9850\n"
          ]
        }
      ],
      "source": [
        "input_dim = 64\n",
        "output_dim = 10\n",
        "lr = 5e-5\n",
        "num_epochs = 20\n",
        "batch_size = 16\n",
        "\n",
        "trainval_ids = train_ids + val_ids\n",
        "\n",
        "trainval_dataset = PollinateDataset(\n",
        "    csv_file=os.path.join(dataset_folder, 'train.csv'),\n",
        "    dataset_folder=os.path.join(dataset_folder, 'train'),\n",
        "    channels=channels,\n",
        "    selected_ids=trainval_ids,\n",
        "    transform=train_transform\n",
        ")\n",
        "\n",
        "# Initialize the model, device, optimizer, and criterion\n",
        "num_classes = len(set(train_dataset.df['class']))\n",
        "model = get_pretrained_resnet(num_classes).to(device)\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Load the training and validation data loaders\n",
        "\n",
        "# Initialize the lists to store the training and validation losses and accuracies\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "val_losses = []\n",
        "val_accs = []\n",
        "best_loss = 0.0\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    # CREATE BATCHES\n",
        "    train_loader = DataLoader(trainval_dataset, batch_size=batch_size, shuffle=True)\n",
        "    train_loss, train_acc = train(model, device, train_loader, optimizer, criterion, epoch)\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
        "\n",
        "torch.save(model.state_dict(),  'final_weights.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUfxQ8GhIew_"
      },
      "source": [
        "# Compute the prediction on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsNhcAl2Ief0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9612794612794613\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Crea il dataset e loader\n",
        "test_dataset = PollinateDataset(\n",
        "    csv_file=os.path.join(dataset_folder, 'train.csv'),  \n",
        "    dataset_folder=os.path.join(dataset_folder, 'train'),\n",
        "    channels=channels,\n",
        "    selected_ids=test_ids,\n",
        "    transform=testval_transform\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "model.load_state_dict(torch.load('final_weights.pth'))\n",
        "model.eval()\n",
        "\n",
        "test_predictions = []\n",
        "true_labels = []\n",
        "test_prob = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for ids, inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = model(inputs)\n",
        "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
        "        _, predicted = torch.max(probs, 1)\n",
        "\n",
        "        test_predictions.extend(predicted.cpu().numpy())\n",
        "        test_prob.extend(probs.cpu().numpy())\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "# Accuracy\n",
        "acc = (np.array(test_predictions) == np.array(true_labels)).mean()\n",
        "print(\"Test Accuracy:\", acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jPH9UDaoIi4Q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ -2.5505,   6.2949, -23.6103, -23.9749, -22.3061, -21.3416, -22.8903,\n",
            "         -22.1036, -22.4021, -19.6203],\n",
            "        [ -1.6605,   6.3218, -23.2537, -24.7811, -21.7051, -23.6336, -23.4781,\n",
            "         -25.4486, -25.9040, -23.0606],\n",
            "        [  3.7169,   0.0809, -29.0194, -29.0389, -27.8692, -27.4983, -29.2978,\n",
            "         -30.1032, -31.4293, -29.7936],\n",
            "        [  2.7896,   1.6813, -31.0087, -32.2892, -30.2858, -27.8040, -30.8533,\n",
            "         -29.9769, -31.4373, -28.7290],\n",
            "        [  1.3196,   4.4041, -29.8822, -28.6497, -27.6455, -26.2862, -28.9228,\n",
            "         -29.7355, -30.5645, -26.9077],\n",
            "        [ -2.3715,   7.9302, -46.5500, -46.9655, -45.7877, -47.1357, -45.3250,\n",
            "         -45.0015, -48.7084, -45.7110],\n",
            "        [ -3.3131,   6.2960, -17.6418, -17.2197, -16.3994, -15.2296, -16.8975,\n",
            "         -16.4865, -16.5364, -14.0785],\n",
            "        [  0.1601,   9.3648, -50.7262, -48.7365, -49.1076, -50.1266, -49.5135,\n",
            "         -47.1522, -50.2207, -51.3048]])\n",
            "tensor([[1.4403e-04, 9.9986e-01, 1.0287e-13, 7.1434e-14, 3.7904e-13, 9.9437e-13,\n",
            "         2.1134e-13, 4.6408e-13, 3.4432e-13, 5.5603e-12],\n",
            "        [3.4136e-04, 9.9966e-01, 1.4302e-13, 3.1049e-14, 6.7287e-13, 9.7816e-14,\n",
            "         1.1428e-13, 1.5929e-14, 1.0101e-14, 1.7349e-13],\n",
            "        [9.7432e-01, 2.5681e-02, 5.9085e-15, 5.7946e-15, 1.8665e-14, 2.7047e-14,\n",
            "         4.4728e-15, 1.9990e-15, 5.3073e-16, 2.7242e-15],\n",
            "        [7.5181e-01, 2.4819e-01, 1.5766e-15, 4.3811e-16, 3.2484e-15, 3.8858e-14,\n",
            "         1.8415e-15, 4.4240e-15, 1.0270e-15, 1.5409e-14],\n",
            "        [4.3748e-02, 9.5625e-01, 1.2308e-15, 4.2214e-15, 1.1524e-14, 4.4868e-14,\n",
            "         3.2126e-15, 1.4253e-15, 6.2216e-16, 2.4099e-14],\n",
            "        [3.3576e-05, 9.9997e-01, 2.1855e-24, 1.4425e-24, 4.6842e-24, 1.2167e-24,\n",
            "         7.4399e-24, 1.0282e-23, 2.5244e-25, 5.0573e-24],\n",
            "        [6.7108e-05, 9.9993e-01, 4.0173e-11, 6.1271e-11, 1.3915e-10, 4.4824e-10,\n",
            "         8.4557e-11, 1.2754e-10, 1.2133e-10, 1.4173e-09],\n",
            "        [1.0055e-04, 9.9990e-01, 7.9937e-27, 5.8463e-26, 4.0336e-26, 1.4560e-26,\n",
            "         2.6879e-26, 2.8505e-25, 1.3253e-26, 4.4822e-27]])\n"
          ]
        }
      ],
      "source": [
        "print(outputs)\n",
        "print(torch.nn.functional.softmax(outputs, dim=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20, Train Loss: 0.0206, Train Acc: 0.8563\n",
            "Epoch 2/20, Train Loss: 0.0134, Train Acc: 0.9172\n",
            "Epoch 3/20, Train Loss: 0.0098, Train Acc: 0.9410\n",
            "Epoch 4/20, Train Loss: 0.0084, Train Acc: 0.9520\n",
            "Epoch 5/20, Train Loss: 0.0074, Train Acc: 0.9562\n",
            "Epoch 6/20, Train Loss: 0.0068, Train Acc: 0.9594\n",
            "Epoch 7/20, Train Loss: 0.0058, Train Acc: 0.9669\n",
            "Epoch 8/20, Train Loss: 0.0052, Train Acc: 0.9698\n",
            "Epoch 9/20, Train Loss: 0.0045, Train Acc: 0.9734\n",
            "Epoch 10/20, Train Loss: 0.0041, Train Acc: 0.9751\n",
            "Epoch 11/20, Train Loss: 0.0037, Train Acc: 0.9785\n",
            "Epoch 12/20, Train Loss: 0.0038, Train Acc: 0.9772\n",
            "Epoch 13/20, Train Loss: 0.0041, Train Acc: 0.9768\n",
            "Epoch 14/20, Train Loss: 0.0034, Train Acc: 0.9801\n",
            "Epoch 15/20, Train Loss: 0.0035, Train Acc: 0.9815\n",
            "Epoch 16/20, Train Loss: 0.0029, Train Acc: 0.9835\n",
            "Epoch 17/20, Train Loss: 0.0027, Train Acc: 0.9834\n",
            "Epoch 18/20, Train Loss: 0.0026, Train Acc: 0.9862\n",
            "Epoch 19/20, Train Loss: 0.0030, Train Acc: 0.9828\n",
            "Epoch 20/20, Train Loss: 0.0029, Train Acc: 0.9834\n"
          ]
        }
      ],
      "source": [
        "# Crea il dataset completo di training (usa tutto train.csv)\n",
        "full_train_dataset = PollinateDataset(\n",
        "    csv_file=os.path.join(dataset_folder, 'train.csv'),\n",
        "    dataset_folder=os.path.join(dataset_folder, 'train'),\n",
        "    channels=channels,\n",
        "    transform=train_transform\n",
        ")\n",
        "\n",
        "full_train_loader = DataLoader(full_train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Initialize the model, device, optimizer, and criterion\n",
        "num_classes = len(set(train_dataset.df['class']))\n",
        "model = get_pretrained_resnet(num_classes).to(device)\n",
        "\n",
        "# Si addestra l'intera rete\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "## PROVARE A MODIFICARE ANCHE NELL'ALTRO\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train(model, device, full_train_loader, optimizer, criterion, epoch)\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
        "\n",
        "torch.save(model.state_dict(), 'final_weights_full.pth')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "test_folder = os.path.join(dataset_folder, 'test')\n",
        "test_dataset = PollinateTestDataset(\n",
        "    dataset_folder=test_folder,\n",
        "    channels=channels,\n",
        "    transform=testval_transform\n",
        ")\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "model.load_state_dict(torch.load('final_weights_full.pth'))\n",
        "model.eval()\n",
        "\n",
        "test_ids_out = []\n",
        "test_predictions = []\n",
        "test_prob = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for ids, inputs in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = model(inputs)\n",
        "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
        "        _, predicted = torch.max(probs, 1)\n",
        "        test_ids_out.extend(ids)\n",
        "        test_predictions.extend(predicted.cpu().numpy())\n",
        "        test_prob.extend(probs.cpu().numpy())\n",
        "\n",
        "df_pred = pd.DataFrame({'Img': test_ids_out, 'class': test_predictions})\n",
        "df_pred.to_csv('test_predictions4.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
